{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##데이터 불러오기\n",
    "아파트매매가격 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/월별동향_아파트_매매가격.xlsx',header=None)\n",
    "대출금리 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/예금은행_대출금리_신규취급액_기준__20241023164433.xlsx',header=None)\n",
    "지역내총생산 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/지역내총생산GRDP(2010~2021년).xlsx',sheet_name=1,header=None)\n",
    "연도별세대수 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/인구추이_20241023165747.xlsx',sheet_name=0,header=None)\n",
    "아파트매매거래량 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/상세기준별거래량(아파트매매)-거래규모.xlsx',header=None)\n",
    "공급물가지수 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/국내공급물가지수_20241023165502.xlsx',header=None)\n",
    "주택가격지수 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/주택가격지수_20241023170729.xlsx',header=None)\n",
    "소비자물가지수 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/소비자물가지수.xlsx',header=None)\n",
    "전출_전입수 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/인구.xlsx',header=None)\n",
    "이혼_혼인_매매가격지수 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/가족_주거와 교통.xlsx',header=None)\n",
    "경제활동인구_실업자 = pd.read_excel('/Users/kimboyun/Desktop/코드/Capstone-Design/dataset/경제활동인구&실업자.xlsx',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "###아파트매매가격\n",
    "아파트매매가격 = 아파트매매가격.iloc[[0,47],1:].T\n",
    "아파트매매가격.columns = ['날짜','아파트매매가격']\n",
    "아파트매매가격['날짜'] = pd.to_datetime(아파트매매가격['날짜'].astype(str).apply(lambda x : x.ljust(7, '0')))\n",
    "#아파트매매가격_new.head()\n",
    "\n",
    "###대출금리\n",
    "대출금리 = 대출금리.iloc[:,1:].T\n",
    "대출금리.columns = ['날짜','주택담보대출금리']\n",
    "대출금리['날짜'] = pd.to_datetime(대출금리['날짜'].astype(str).apply(lambda x : x.ljust(7, '0')), format='%Y.%m')\n",
    "\n",
    "\n",
    "###지역내총생산(연 단위)\n",
    "지역내총생산 = 지역내총생산.iloc[[3,8],1:12].T\n",
    "지역내총생산.columns = ['년도','지역내총생산']\n",
    "지역내총생산['년도'] = 지역내총생산['년도'].apply(lambda x: pd.to_datetime(str(x), format='%Y년'))\n",
    "지역내총생산['날짜'] = 지역내총생산['년도'].dt.strftime(\"%Y-%m-%d\")\n",
    "지역내총생산 = 지역내총생산.iloc[:,1:3]\n",
    "지역내총생산 = 지역내총생산[['날짜','지역내총생산']]\n",
    "지역내총생산['날짜'] = pd.to_datetime(지역내총생산['날짜'].astype(str))\n",
    "#지역내총생산_new.head()\n",
    "\n",
    "###연도별세대수(연 단위)\n",
    "연도별세대수 = 연도별세대수.iloc[:,1:].T\n",
    "연도별세대수.columns = ['년도','연도별세대수']\n",
    "연도별세대수['년도'] = 연도별세대수['년도'].apply(lambda x: pd.to_datetime(str(x), format='%Y'))\n",
    "연도별세대수['날짜'] = 연도별세대수['년도'].dt.strftime(\"%Y-%m-%d\")\n",
    "연도별세대수 = 연도별세대수.iloc[:,1:3]\n",
    "연도별세대수 = 연도별세대수[['날짜','연도별세대수']]\n",
    "연도별세대수['날짜'] = pd.to_datetime(연도별세대수['날짜'].astype(str))\n",
    "#연도별세대수_new.head()\n",
    "\n",
    "###아파트매매거래량\n",
    "아파트매매거래량 = 아파트매매거래량.iloc[[0,1],1:].T\n",
    "아파트매매거래량.columns = ['날짜','아파트매매거래량']\n",
    "아파트매매거래량['날짜'] = pd.to_datetime(아파트매매거래량['날짜'].astype(str).apply(lambda x : x.ljust(6, '0')), format='\\'%y.%m')\n",
    "#아파트매매거래량.head()\n",
    "\n",
    "###공급물가지수\n",
    "공급물가지수 = 공급물가지수.iloc[:,1:].T\n",
    "공급물가지수.columns = ['날짜','공급물가지수']\n",
    "공급물가지수['날짜'] = pd.to_datetime(공급물가지수['날짜'].astype(str).apply(lambda x : x.ljust(7, '0')), format='%Y.%m')\n",
    "#공급물가지수_new.head()\n",
    "\n",
    "###주택가격지수(연단위)\n",
    "주택가격지수 = 주택가격지수.iloc[[0,2],[5,9,13,17,21,25,29,33,37,41,45]].T\n",
    "주택가격지수.columns = ['년도','주택가격지수']\n",
    "주택가격지수['년도'] = 주택가격지수['년도'].apply(lambda x: pd.to_datetime(str(x), format='%Y'))\n",
    "주택가격지수['날짜'] = 주택가격지수['년도'].dt.strftime(\"%Y-%m-%d\")\n",
    "주택가격지수 = 주택가격지수.iloc[:,1:3]\n",
    "주택가격지수 = 주택가격지수[['날짜','주택가격지수']]\n",
    "주택가격지수['날짜'] = pd.to_datetime(주택가격지수['날짜'].astype(str))\n",
    "#주택가격지수_new.head()\n",
    "\n",
    "###소비자물가지수\n",
    "소비자물가지수 = 소비자물가지수.iloc[:,1:].T\n",
    "소비자물가지수.columns = ['날짜','소비자물가지수']\n",
    "소비자물가지수['날짜'] = pd.to_datetime(소비자물가지수['날짜'].astype(str).apply(lambda x : x.ljust(7, '0')), format='%Y.%m')\n",
    "#소비자물가지수_new.head()\n",
    "\n",
    "###전출_전입수\n",
    "전출_전입수 = 전출_전입수.iloc[[0,3,4,5,6],3:].T\n",
    "전출_전입수.columns = ['날짜','전출인구','전입인구','사망자수','출생아수']\n",
    "전출_전입수['날짜'] = pd.to_datetime(전출_전입수['날짜'].astype(str).apply(lambda x : x.ljust(7, '0')), format='%Y.%m')\n",
    "#전출_전입수_new.head()\n",
    "\n",
    "###이혼_혼인_매매가격지수\n",
    "이혼_혼인_매매가격지수 = 이혼_혼인_매매가격지수.iloc[[0,1,2,7],3:].T\n",
    "이혼_혼인_매매가격지수.columns = ['날짜','이혼건수','혼인건수','아파트매매가격지수']\n",
    "이혼_혼인_매매가격지수['날짜'] = pd.to_datetime(이혼_혼인_매매가격지수['날짜'].astype(str).apply(lambda x : x.ljust(7, '0')), format='%Y.%m')\n",
    "#이혼_혼인_매매가격지수_new.head()\n",
    "\n",
    "\n",
    "###실업자 수\n",
    "실업자_분기 = 경제활동인구_실업자.iloc[[0,2],[4,6,8,10,12,14,16,18,20]].T\n",
    "실업자_분기.columns = ['년도','실업자 수']\n",
    "실업자_분기['년도'] = 실업자_분기['년도'].apply(lambda x: pd.to_datetime(str(x), format='%Y %m/%d'))\n",
    "실업자_분기['년'] = 실업자_분기['년도'].dt.strftime(\"%Y\")\n",
    "실업자_분기['분기'] = 실업자_분기['년도'].dt.strftime(\"%m\")\n",
    "실업자_분기 = 실업자_분기.iloc[:,0:4]\n",
    "실업자_분기['월변환'] = 실업자_분기['분기'].map({'01': '01', '02': '04', '03': '07', '04': '10'})\n",
    "실업자_분기['날짜'] = 실업자_분기['년'].astype(str) + '-' + 실업자_분기['월변환'].astype(str).str.zfill(2) + '-' + '01'\n",
    "실업자_분기 = 실업자_분기.iloc[:,[1,5]]\n",
    "실업자_분기_new = 실업자_분기[['날짜','실업자 수']]\n",
    "#실업자_분기_new.head()\n",
    "실업자_반기 = 경제활동인구_실업자.iloc[[0,2],[22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58]].T\n",
    "실업자_반기.columns = ['년도','실업자 수']\n",
    "실업자_반기['년도'] = 실업자_반기['년도'].apply(lambda x: pd.to_datetime(str(x), format='%Y %m/%d'))\n",
    "실업자_반기['년'] = 실업자_반기['년도'].dt.strftime(\"%Y\")\n",
    "실업자_반기['반기'] = 실업자_반기['년도'].dt.strftime(\"%m\")\n",
    "실업자_반기 = 실업자_반기.iloc[:,0:4]\n",
    "실업자_반기['월변환'] = 실업자_반기['반기'].map({'01': '01', '02': '07'})\n",
    "실업자_반기['날짜'] = 실업자_반기['년'].astype(str) + '-' + 실업자_반기['월변환'].astype(str).str.zfill(2) + '-' + '01'\n",
    "실업자_반기 = 실업자_반기.iloc[:,[1,5]]\n",
    "실업자_반기_new = 실업자_반기[['날짜','실업자 수']]\n",
    "#실업자_반기_new.head()\n",
    "실업자 = pd.concat([실업자_분기_new, 실업자_반기_new], axis = 0)\n",
    "실업자['날짜'] = pd.to_datetime(실업자['날짜'].astype(str))\n",
    "#실업자_new.head(20)\n",
    "\n",
    "\n",
    "###경제활동인구\n",
    "경제활동인구_분기 = 경제활동인구_실업자.iloc[[0,2],[3,5,7,9,11,13,15,17,19]].T\n",
    "경제활동인구_분기.columns = ['년도','경제활동인구']\n",
    "경제활동인구_분기['년도'] = 경제활동인구_분기['년도'].apply(lambda x: pd.to_datetime(str(x), format='%Y %m/%d'))\n",
    "경제활동인구_분기['년'] = 경제활동인구_분기['년도'].dt.strftime(\"%Y\")\n",
    "경제활동인구_분기['분기'] = 경제활동인구_분기['년도'].dt.strftime(\"%m\")\n",
    "경제활동인구_분기 = 경제활동인구_분기.iloc[:,0:4]\n",
    "경제활동인구_분기['월변환'] = 경제활동인구_분기['분기'].map({'01': '01', '02': '04', '03': '07', '04': '10'})\n",
    "경제활동인구_분기['날짜'] = 경제활동인구_분기['년'].astype(str) + '-' + 경제활동인구_분기['월변환'].astype(str).str.zfill(2) + '-' + '01'\n",
    "경제활동인구_분기 = 경제활동인구_분기.iloc[:,[1,5]]\n",
    "경제활동인구_분기_new = 경제활동인구_분기[['날짜','경제활동인구']]\n",
    "#경제활동인구_분기_new.head()\n",
    "경제활동인구_반기 = 경제활동인구_실업자.iloc[[0,2],[21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57]].T\n",
    "경제활동인구_반기.columns = ['년도','경제활동인구']\n",
    "경제활동인구_반기['년도'] = 경제활동인구_반기['년도'].apply(lambda x: pd.to_datetime(str(x), format='%Y %m/%d'))\n",
    "경제활동인구_반기['년'] = 경제활동인구_반기['년도'].dt.strftime(\"%Y\")\n",
    "경제활동인구_반기['반기'] = 경제활동인구_반기['년도'].dt.strftime(\"%m\")\n",
    "경제활동인구_반기 = 경제활동인구_반기.iloc[:,0:4]\n",
    "경제활동인구_반기['월변환'] = 경제활동인구_반기['반기'].map({'01': '01', '02': '07'})\n",
    "경제활동인구_반기['날짜'] = 경제활동인구_반기['년'].astype(str) + '-' + 경제활동인구_반기['월변환'].astype(str).str.zfill(2) + '-' + '01'\n",
    "경제활동인구_반기 = 경제활동인구_반기.iloc[:,[1,5]]\n",
    "경제활동인구_반기_new = 경제활동인구_반기[['날짜','경제활동인구']]\n",
    "#경제활동인구_반기_new.head()\n",
    "경제활동인구 = pd.concat([경제활동인구_분기_new, 경제활동인구_반기_new], axis = 0)\n",
    "경제활동인구['날짜'] = pd.to_datetime(경제활동인구['날짜'].astype(str))\n",
    "#print(경제활동인구_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 합치기\n",
    "데이터셋 = 아파트매매가격.merge(대출금리, on='날짜', how='outer')\\\n",
    ".merge(지역내총생산, how='outer', on='날짜')\\\n",
    ".merge(연도별세대수, how='outer', on='날짜')\\\n",
    ".merge(아파트매매거래량, how='outer', on='날짜')\\\n",
    ".merge(공급물가지수, how='outer', on='날짜')\\\n",
    ".merge(주택가격지수, how='outer', on='날짜')\\\n",
    ".merge(소비자물가지수, how='outer', on='날짜')\\\n",
    ".merge(전출_전입수, how='outer', on='날짜')\\\n",
    ".merge(이혼_혼인_매매가격지수, how='outer', on='날짜')\\\n",
    ".merge(실업자, how='outer', on='날짜')\\\n",
    ".merge(경제활동인구, how='outer', on='날짜')\n",
    "데이터셋['날짜'] = 데이터셋['날짜'].dt.strftime(\"%Y.%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/725916345.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  데이터셋 = 데이터셋.ffill().bfill()\n"
     ]
    }
   ],
   "source": [
    "##결측값 채우기\n",
    "데이터셋.isnull().sum()\n",
    "데이터셋 = 데이터셋.ffill().bfill()\n",
    "\n",
    "##다음달매매가격 데이터 추가\n",
    "다음달매매가격 = 데이터셋.iloc[147:279,1].to_frame()\n",
    "다음달매매가격.columns = ['다음달아파트매매가격']\n",
    "다음달매매가격.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "#2012~2022 범위지정 및 사용할 데이터만 추출\n",
    "데이터셋_ = 데이터셋.iloc[146:278,1:18]\n",
    "데이터셋_.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataset = pd.concat([데이터셋_,다음달매매가격], axis=1)\n",
    "\n",
    "dataset.to_excel(\"dataframe.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE1 분석 (상관계수를 이용한)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관계수도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음달아파트매매가격과 다른 변수 간의 상관계수 (내림차순):\n",
      "아파트매매가격      0.996741\n",
      "아파트매매가격지수    0.990187\n",
      "소비자물가지수      0.923124\n",
      "연도별세대수       0.913826\n",
      "지역내총생산       0.778835\n",
      "사망자수         0.624145\n",
      "공급물가지수       0.573315\n",
      "경제활동인구       0.088782\n",
      "주택가격지수       0.071218\n",
      "실업자 수       -0.014333\n",
      "주택담보대출금리    -0.115616\n",
      "아파트매매거래량    -0.287817\n",
      "전입인구        -0.416965\n",
      "전출인구        -0.481476\n",
      "이혼건수        -0.677962\n",
      "혼인건수        -0.732221\n",
      "출생아수        -0.863166\n",
      "Name: 다음달아파트매매가격, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# 상관관계 분석을 위한 변수 목록 (날짜 변수를 제외한 나머지 변수)\n",
    "columns_to_analyze = ['아파트매매가격', '주택담보대출금리', '지역내총생산', '연도별세대수', '아파트매매거래량', \n",
    "                       '공급물가지수', '주택가격지수', '소비자물가지수', '전출인구', '전입인구', \n",
    "                       '사망자수', '출생아수', '이혼건수', '혼인건수', \n",
    "                       '아파트매매가격지수', '실업자 수', '경제활동인구', '다음달아파트매매가격']\n",
    "\n",
    "# 상관계수 계산\n",
    "correlation_matrix = dataset[columns_to_analyze].corr()\n",
    "\n",
    "# 다음달아파트매매가격과 다른 변수 간의 상관계수만 추출\n",
    "target_correlation = correlation_matrix['다음달아파트매매가격'].drop('다음달아파트매매가격')\n",
    "\n",
    "# 상관계수 내림차순 정렬\n",
    "target_correlation_sorted = target_correlation.sort_values(ascending=False)\n",
    "\n",
    "# 상관계수 출력\n",
    "print(\"다음달아파트매매가격과 다른 변수 간의 상관계수 (내림차순):\")\n",
    "print(target_correlation_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.0 ~ 0.1: 매우 낮은 상관관계 (혹은 상관관계 없음)\n",
    "#0.1 ~ 0.3: 낮은 상관관계\n",
    "#0.3 ~ 0.5: 중간 정도의 상관관계\n",
    "#0.5 ~ 0.7: 높은 상관관계\n",
    "#0.7 ~ 0.9: 매우 높은 상관관계\n",
    "#0.9 ~ 1.0: 완벽한 상관관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관계수가 0.5 이하인 변수(공급물가지수, 살업자수, 주택가격지수, 경제활동인구, 아파트매매거래량, 주택담보대출금리, 전입인구, 전출인구)를 모델링과정에서 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터분할 및 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 특성과 타겟 변수 설정\n",
    "features = ['아파트매매가격', '지역내총생산', '연도별세대수', \n",
    "            '소비자물가지수', '공급물가지수', '사망자수', '출생아수', '이혼건수',\n",
    "            '혼인건수', '아파트매매가격지수']\n",
    "target = ['다음달아파트매매가격']\n",
    "\n",
    "# Assuming scaled_df is defined elsewhere and is already scaled\n",
    "X = dataset[features]\n",
    "y = dataset[target]\n",
    "\n",
    "# 시계열 데이터이므로 시간 순서를 고려한 훈련-테스트 데이터 분할\n",
    "train_size = int(len(X) * 0.7)  # 데이터의 70%는 학습용, 30%는 테스트용\n",
    "X_train, X_test, y_train, y_test = X[:train_size], X[train_size:], y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    아파트매매가격  지역내총생산  연도별세대수   소비자물가지수  공급물가지수      사망자수      출생아수      이혼건수  \\\n",
      "0  0.175666     0.0     0.0  0.000000  111.07  0.319372  0.981891  0.392157   \n",
      "1  0.170294     0.0     0.0  0.038534  111.52  0.293194  0.704225  0.441176   \n",
      "2  0.162879     0.0     0.0  0.041430  112.48  0.460733  0.770624  0.549020   \n",
      "3  0.156756     0.0     0.0  0.040428  112.65  0.335079  0.726358  0.166667   \n",
      "4  0.151855     0.0     0.0  0.058693  111.85  0.225131  0.700201  0.892157   \n",
      "\n",
      "       혼인건수  아파트매매가격지수  \n",
      "0  0.562205   0.371728  \n",
      "1  0.437795   0.361257  \n",
      "2  0.604724   0.345550  \n",
      "3  0.472441   0.335079  \n",
      "4  0.585827   0.324607  \n",
      "     아파트매매가격  지역내총생산    연도별세대수   소비자물가지수  공급물가지수      사망자수      출생아수  \\\n",
      "92  0.963116  1.0000  1.000000  0.952445  102.81  0.434555  0.128773   \n",
      "93  0.986084  1.0000  1.000000  0.979953  102.39  0.549738  0.144869   \n",
      "94  1.011598  1.0000  1.000000  0.917585  101.83  0.497382  0.016097   \n",
      "95  1.042777  1.0000  1.000000  0.944092  102.17  0.528796 -0.096579   \n",
      "96  1.260436  1.1351  1.461596  0.985410  102.44  0.643979  0.154930   \n",
      "\n",
      "        이혼건수      혼인건수  아파트매매가격지수  \n",
      "92  0.088235  0.085039   0.900524  \n",
      "93  0.362745  0.200000   0.937173  \n",
      "94  0.421569  0.138583   0.979058  \n",
      "95  0.411765  0.385827   1.031414  \n",
      "96  0.401961  0.152756   1.062827  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/3170447892.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[columns_to_scale_X] = scaler_X.fit_transform(X_train[columns_to_scale_X])\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/3170447892.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[columns_to_scale_X] = scaler_X.transform(X_test[columns_to_scale_X])\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/3170447892.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train[columns_to_scale_y] = scaler_y.fit_transform(y_train[columns_to_scale_y])\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/3170447892.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test[columns_to_scale_y] = scaler_y.transform(y_test[columns_to_scale_y])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "\n",
    "# 정규화할 열을 선택\n",
    "columns_to_scale_X = ['아파트매매가격', '지역내총생산', '연도별세대수', \n",
    "                    '소비자물가지수', '사망자수', '출생아수', '이혼건수',\n",
    "                    '혼인건수', '아파트매매가격지수']\n",
    "columns_to_scale_y = ['다음달아파트매매가격']\n",
    "\n",
    "# 스케일링 적용 (선택한 열들에 대해서만)\n",
    "X_train[columns_to_scale_X] = scaler_X.fit_transform(X_train[columns_to_scale_X])\n",
    "X_test[columns_to_scale_X] = scaler_X.transform(X_test[columns_to_scale_X])\n",
    "y_train[columns_to_scale_y] = scaler_y.fit_transform(y_train[columns_to_scale_y])\n",
    "y_test[columns_to_scale_y] = scaler_y.transform(y_test[columns_to_scale_y])\n",
    "\n",
    "# 스케일링된 데이터프레임을 새로운 변수에 저장\n",
    "scaled_X_train = X_train.copy()\n",
    "scaled_X_test = X_test.copy()\n",
    "scaled_y_train = y_train.copy()\n",
    "scaled_y_test = y_test.copy()\n",
    "\n",
    "# 데이터 확인\n",
    "print(scaled_X_train.head(5))\n",
    "print(scaled_X_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.009620887026234736\n",
      "Root Mean Squared Error (RMSE): 0.09808612045664125\n",
      "Mean Absolute Error (MAE): 0.05729038035738978\n",
      "Mean Absolute Percentage Error (MAPE): 0.030267629206859593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# xgboost 모델 생성 및 학습\n",
    "model = LinearRegression()\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "C_regression_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "C_regression_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "C_regression_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", C_regression_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", C_regression_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", C_regression_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.9114281516615405\n",
      "Root Mean Squared Error (RMSE): 0.9546874628178273\n",
      "Mean Absolute Error (MAE): 0.831245876573781\n",
      "Mean Absolute Percentage Error (MAPE): 0.4291142321938934\n"
     ]
    }
   ],
   "source": [
    "# xgboost 모델 생성 및 학습\n",
    "model = xgb.XGBRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "C_xgboost_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "C_xgboost_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "C_xgboost_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", C_xgboost_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", C_xgboost_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", C_xgboost_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.2807612852176327\n",
      "Root Mean Squared Error (RMSE): 1.1317072436004079\n",
      "Mean Absolute Error (MAE): 1.0148554674446513\n",
      "Mean Absolute Percentage Error (MAPE): 0.535380757432524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# adaboost 모델 생성 및 학습\n",
    "model = AdaBoostRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "C_adaboost_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "C_adaboost_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "C_adaboost_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", C_adaboost_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", C_adaboost_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", C_adaboost_mape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.9681433905488117\n",
      "Root Mean Squared Error (RMSE): 0.983942778086618\n",
      "Mean Absolute Error (MAE): 0.8596030199374824\n",
      "Mean Absolute Percentage Error (MAPE): 0.44486244395778585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 랜덤 포레스트 모델 생성 및 학습\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "C_RandomForest_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "C_RandomForest_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "C_RandomForest_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", C_RandomForest_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", C_RandomForest_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", C_RandomForest_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.2903389684328928\n",
      "Root Mean Squared Error (RMSE): 1.1359308818906602\n",
      "Mean Absolute Error (MAE): 1.0252804686444947\n",
      "Mean Absolute Percentage Error (MAPE): 0.543692413001323\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 모델 생성 \n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = regressor.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "C_DecisionTree_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "C_DecisionTree_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "C_DecisionTree_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", C_DecisionTree_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", C_DecisionTree_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", C_DecisionTree_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0437 - val_loss: 0.4406\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0201 - val_loss: 0.2903\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0101 - val_loss: 0.2114\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0098 - val_loss: 0.1686\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.1618\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0096 - val_loss: 0.1618\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061 - val_loss: 0.1661\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0091 - val_loss: 0.1391\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.1089\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0896\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0058 - val_loss: 0.0849\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0058 - val_loss: 0.0948\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0923\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - val_loss: 0.0383\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0036 - val_loss: 0.0192\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0079 - val_loss: 0.0127\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - val_loss: 0.0140\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0149\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0275\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0467\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0053 - val_loss: 0.0410\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0283\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0168\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0063 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0138\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0229\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0300\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0268\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0126\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0036 - val_loss: 0.0227\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0049 - val_loss: 0.0872\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0083 - val_loss: 0.1128\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.0920\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0723\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0067 - val_loss: 0.0669\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0586\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0425\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Mean Squared Error (MSE): 0.00727361205400238\n",
      "Root Mean Squared Error (RMSE): 0.08528547387452555\n",
      "Mean Absolute Error (MAE): 0.07408351103464762\n",
      "Mean Absolute Percentage Error (MAPE): 0.07408351103464762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 특성과 타겟 변수 설정\n",
    "features = ['아파트매매가격', '지역내총생산', '연도별세대수', \n",
    "            '소비자물가지수', '공급물가지수','사망자수', '출생아수', '이혼건수',\n",
    "            '혼인건수', '아파트매매가격지수']\n",
    "target = ['다음달아파트매매가격']\n",
    "\n",
    "# 시계열 데이터이므로 시간 순서를 고려한 훈련-테스트 데이터 분할\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "X_train, X_test = dataset[features][:train_size], dataset[features][train_size:]\n",
    "y_train, y_test = dataset[target][:train_size], dataset[target][train_size:]\n",
    "\n",
    "# 스케일링 (훈련 세트에만 피팅하고 변환)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = np.clip(scaler_X.transform(X_test),0,1)  # fit_transform이 아닌 transform 사용\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = np.clip(scaler_y.transform(y_test),0,1)\n",
    "\n",
    "# 시계열 데이터 형식으로 변환 (시퀀스 생성)\n",
    "def create_sequences(X, y, seq_length=10):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 10  # 시퀀스 길이 설정\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 조기종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=32, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test_seq)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test_seq, y_pred)\n",
    "C_LSTM_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "C_LSTM_mae = mean_absolute_error(y_test_seq, y_pred)  # MAE 계산\n",
    "C_LSTM_mape = mean_absolute_percentage_error(y_test_seq, y_pred)  # MAPE 계산\n",
    "\n",
    "# 성능 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", C_LSTM_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", C_LSTM_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", C_LSTM_mape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_Linear_regression (RMSE): 0.09808612045664125\n",
      "C_XGboost           (RMSE): 0.9546874628178273\n",
      "C_ADAboost          (RMSE): 1.1317072436004079\n",
      "C_Random_Forest     (RMSE): 0.983942778086618\n",
      "C_Decision_Tree     (RMSE): 1.1359308818906602\n",
      "C_LSTM              (RMSE): 0.08528547387452555\n"
     ]
    }
   ],
   "source": [
    "print(\"C_Linear_regression (RMSE):\", C_regression_rmse)\n",
    "print(\"C_XGboost           (RMSE):\", C_xgboost_rmse)\n",
    "print(\"C_ADAboost          (RMSE):\", C_adaboost_rmse)\n",
    "print(\"C_Random_Forest     (RMSE):\", C_RandomForest_rmse)\n",
    "print(\"C_Decision_Tree     (RMSE):\", C_DecisionTree_rmse)\n",
    "print(\"C_LSTM              (RMSE):\", C_LSTM_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_Linear_regression (mae): 0.05729038035738978\n",
      "C_XGboost           (mae): 0.831245876573781\n",
      "C_ADAboost          (mae): 1.0148554674446513\n",
      "C_Random_Forest     (mae): 0.8596030199374824\n",
      "C_Decision_Tree     (mae): 1.0252804686444947\n",
      "C_LSTM              (mae): 0.07408351103464762\n"
     ]
    }
   ],
   "source": [
    "print(\"C_Linear_regression (mae):\", C_regression_mae)\n",
    "print(\"C_XGboost           (mae):\", C_xgboost_mae)\n",
    "print(\"C_ADAboost          (mae):\", C_adaboost_mae)\n",
    "print(\"C_Random_Forest     (mae):\", C_RandomForest_mae)\n",
    "print(\"C_Decision_Tree     (mae):\", C_DecisionTree_mae)\n",
    "print(\"C_LSTM              (mae):\", C_LSTM_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_Linear_regression (mape): 0.030267629206859593\n",
      "C_XGboost           (mape): 0.4291142321938934\n",
      "C_ADAboost          (mape): 0.535380757432524\n",
      "C_Random_Forest     (mape): 0.44486244395778585\n",
      "C_Decision_Tree     (mape): 0.543692413001323\n",
      "C_LSTM              (mape): 0.07408351103464762\n"
     ]
    }
   ],
   "source": [
    "print(\"C_Linear_regression (mape):\", C_regression_mape)\n",
    "print(\"C_XGboost           (mape):\", C_xgboost_mape)\n",
    "print(\"C_ADAboost          (mape):\", C_adaboost_mape)\n",
    "print(\"C_Random_Forest     (mape):\", C_RandomForest_mape)\n",
    "print(\"C_Decision_Tree     (mape):\", C_DecisionTree_mape)\n",
    "print(\"C_LSTM              (mape):\", C_LSTM_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE2 분석 (Random Forest기반의 변수중요도를 이용한)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 기반의 변수중요도 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아파트매매가격: 0.4440988032075226\n",
      "아파트매매가격지수: 0.4090597706928144\n",
      "주택담보대출금리: 0.03587802318161045\n",
      "실업자 수: 0.027666398561233006\n",
      "연도별세대수: 0.02328046889695468\n",
      "지역내총생산: 0.021986483756457623\n",
      "소비자물가지수: 0.019212275580834152\n",
      "출생아수: 0.008890782437983382\n",
      "주택가격지수: 0.005575110566364384\n",
      "공급물가지수: 0.0010345673793862712\n",
      "혼인건수: 0.0009889200799432782\n",
      "사망자수: 0.0009604427400681445\n",
      "아파트매매거래량: 0.0006887106669422959\n",
      "전입인구: 0.00027066097794669974\n",
      "경제활동인구: 0.00016296014419556185\n",
      "전출인구: 0.00015049014935818904\n",
      "이혼건수: 9.51309803847745e-05\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "features = ['아파트매매가격', '주택담보대출금리','지역내총생산', '연도별세대수', '아파트매매거래량', \n",
    "                    '공급물가지수', '주택가격지수','소비자물가지수', '전출인구', '전입인구', \n",
    "                    '사망자수', '출생아수', '이혼건수', '혼인건수', \n",
    "                    '아파트매매가격지수', '실업자 수', '경제활동인구']\n",
    "target = '다음달아파트매매가격'\n",
    "\n",
    "X = dataset[features]\n",
    "y = dataset[target]\n",
    "\n",
    "# 시계열 데이터이므로 시간 순서를 고려한 훈련-테스트 데이터 분할\n",
    "train_size = int(len(X) * 0.7)  # 데이터의 70%는 학습용, 30%는 테스트용\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# 모델 생성 \n",
    "regressor = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Calculate variable importances\n",
    "importances = regressor.feature_importances_\n",
    "\n",
    "# Sort variables by importance\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "sorted_features = np.array(features)[sorted_indices]\n",
    "sorted_importances = importances[sorted_indices]\n",
    "\n",
    "# 변수중요도 출력\n",
    "for feature, importance in zip(sorted_features, sorted_importances):\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.001 미만인  아파트매매거래량, 전입인구, 혼인건수, 전출인구, 경제활동인구, 사망자수, 이혼건수 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터분할 및 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 특성과 타겟 변수 설정\n",
    "features = ['아파트매매가격', '주택담보대출금리','지역내총생산', '연도별세대수', '공급물가지수', \n",
    "                     '주택가격지수','소비자물가지수',  \n",
    "                     '출생아수',  \n",
    "                    '아파트매매가격지수', '실업자 수']\n",
    "target = ['다음달아파트매매가격']\n",
    "\n",
    "# Assuming scaled_df is defined elsewhere and is already scaled\n",
    "X = dataset[features]\n",
    "y = dataset[target]\n",
    "\n",
    "# 시계열 데이터이므로 시간 순서를 고려한 훈련-테스트 데이터 분할\n",
    "train_size = int(len(X) * 0.7)  # 데이터의 70%는 학습용, 30%는 테스트용\n",
    "X_train, X_test, y_train, y_test = X[:train_size], X[train_size:], y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      아파트매매가격  주택담보대출금리  지역내총생산  연도별세대수    공급물가지수  주택가격지수   소비자물가지수      출생아수  \\\n",
      "0   0.175666  1.000000     0.0     0.0  0.914502     0.0  0.000000  0.981891   \n",
      "1   0.170294  0.984556     0.0     0.0  0.938853     0.0  0.038534  0.704225   \n",
      "2   0.162879  0.976834     0.0     0.0  0.990801     0.0  0.041430  0.770624   \n",
      "3   0.156756  0.953668     0.0     0.0  1.000000     0.0  0.040428  0.726358   \n",
      "4   0.151855  0.918919     0.0     0.0  0.956710     0.0  0.058693  0.700201   \n",
      "..       ...       ...     ...     ...       ...     ...       ...       ...   \n",
      "87  0.948929  0.196911     1.0     1.0  0.451299     1.0  0.917585  0.052314   \n",
      "88  0.939519  0.177606     1.0     1.0  0.508658     1.0  0.936630  0.126761   \n",
      "89  0.935556  0.104247     1.0     1.0  0.478355     1.0  0.918699  0.084507   \n",
      "90  0.943722  0.065637     1.0     1.0  0.444805     1.0  0.884842  0.183099   \n",
      "91  0.951331  0.000000     1.0     1.0  0.491883     1.0  0.911349  0.084507   \n",
      "\n",
      "    아파트매매가격지수     실업자 수  \n",
      "0    0.371728  0.486726  \n",
      "1    0.361257  0.486726  \n",
      "2    0.345550  0.486726  \n",
      "3    0.335079  0.353982  \n",
      "4    0.324607  0.353982  \n",
      "..        ...       ...  \n",
      "87   0.874346  0.831858  \n",
      "88   0.858639  0.831858  \n",
      "89   0.853403  0.831858  \n",
      "90   0.863874  1.000000  \n",
      "91   0.879581  1.000000  \n",
      "\n",
      "[92 rows x 10 columns]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/160426930.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[columns_to_scale_X] = scaler_X.fit_transform(X_train[columns_to_scale_X])\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/160426930.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[columns_to_scale_X] = np.clip(scaler_X.transform(X_test[columns_to_scale_X]),0,1)\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/160426930.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train[columns_to_scale_y] = scaler_y.fit_transform(y_train[columns_to_scale_y])\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/160426930.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test[columns_to_scale_y] = np.clip(scaler_y.transform(y_test[columns_to_scale_y]),0,1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "\n",
    "# 정규화할 열을 선택\n",
    "columns_to_scale_X = ['아파트매매가격', '주택담보대출금리','지역내총생산', '연도별세대수', '공급물가지수', \n",
    "                     '주택가격지수','소비자물가지수',  \n",
    "                     '출생아수',  \n",
    "                    '아파트매매가격지수', '실업자 수']\n",
    "columns_to_scale_y = ['다음달아파트매매가격']\n",
    "\n",
    "# 스케일링 적용 (선택한 열들에 대해서만)\n",
    "X_train[columns_to_scale_X] = scaler_X.fit_transform(X_train[columns_to_scale_X])\n",
    "X_test[columns_to_scale_X] = np.clip(scaler_X.transform(X_test[columns_to_scale_X]),0,1)\n",
    "y_train[columns_to_scale_y] = scaler_y.fit_transform(y_train[columns_to_scale_y])\n",
    "y_test[columns_to_scale_y] = np.clip(scaler_y.transform(y_test[columns_to_scale_y]),0,1)\n",
    "\n",
    "# 스케일링된 데이터프레임을 새로운 변수에 저장\n",
    "scaled_X_train = X_train.copy()\n",
    "scaled_X_test = X_test.copy()\n",
    "scaled_y_train = y_train.copy()\n",
    "scaled_y_test = y_test.copy()\n",
    "\n",
    "# 데이터 확인\n",
    "print(scaled_X_train.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.00037929107514392545\n",
      "Root Mean Squared Error (RMSE): 0.019475396662043253\n",
      "Mean Absolute Error (MAE): 0.017274238558609413\n",
      "Mean Absolute Percentage Error (MAPE): 0.017280832728600877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# xgboost 모델 생성 및 학습\n",
    "model = LinearRegression()\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "R_regression_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "R_regression_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "R_regression_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", R_regression_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", R_regression_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", R_regression_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.026187021224117868\n",
      "Root Mean Squared Error (RMSE): 0.16182404402349446\n",
      "Mean Absolute Error (MAE): 0.11466812913774457\n",
      "Mean Absolute Percentage Error (MAPE): 0.11467960482249943\n"
     ]
    }
   ],
   "source": [
    "# xgboost 모델 생성 및 학습\n",
    "model = xgb.XGBRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "R_xgboost_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "R_xgboost_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "R_xgboost_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", R_xgboost_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", R_xgboost_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", R_xgboost_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0343631392887612\n",
      "Root Mean Squared Error (RMSE): 0.18537297345827197\n",
      "Mean Absolute Error (MAE): 0.139610490926461\n",
      "Mean Absolute Percentage Error (MAPE): 0.13962414035818224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# adaboost 모델 생성 및 학습\n",
    "model = AdaBoostRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "R_adaboost_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "R_adaboost_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "R_adaboost_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", R_adaboost_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", R_adaboost_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", R_adaboost_mape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.03425595501222656\n",
      "Root Mean Squared Error (RMSE): 0.18508364328655993\n",
      "Mean Absolute Error (MAE): 0.16112410943382516\n",
      "Mean Absolute Percentage Error (MAPE): 0.16113583734072798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 랜덤 포레스트 모델 생성 및 학습\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "R_RandomForest_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "R_RandomForest_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "R_RandomForest_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", R_RandomForest_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", R_RandomForest_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", R_RandomForest_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.042801406746038974\n",
      "Root Mean Squared Error (RMSE): 0.20688500850965247\n",
      "Mean Absolute Error (MAE): 0.1584103537890443\n",
      "Mean Absolute Percentage Error (MAPE): 0.15842529986012555\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 모델 생성 \n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = regressor.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "R_DecisionTree_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "R_DecisionTree_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "R_DecisionTree_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", R_DecisionTree_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", R_DecisionTree_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", R_DecisionTree_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0383 - val_loss: 0.3229\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0217 - val_loss: 0.1797\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0189 - val_loss: 0.2057\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0132 - val_loss: 0.2323\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0084 - val_loss: 0.2201\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0118 - val_loss: 0.2051\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.1837\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0076 - val_loss: 0.1357\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0077 - val_loss: 0.1108\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0874\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0075 - val_loss: 0.0719\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0072 - val_loss: 0.0762\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0921\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0698\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050 - val_loss: 0.0263\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0113 - val_loss: 0.0058\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0106 - val_loss: 0.0182\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0874\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0102 - val_loss: 0.1377\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0097 - val_loss: 0.0920\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0444\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - val_loss: 0.0368\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0795\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.1077\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0087 - val_loss: 0.0842\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "Mean Squared Error (MSE): 0.0005132813056261417\n",
      "Root Mean Squared Error (RMSE): 0.022655712428130387\n",
      "Mean Absolute Error (MAE): 0.01998599370320638\n",
      "Mean Absolute Percentage Error (MAPE): 0.01998599370320638\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 특성과 타겟 변수 설정\n",
    "features = ['아파트매매가격', '주택담보대출금리','지역내총생산', '연도별세대수', '아파트매매거래량', \n",
    "                     '주택가격지수','소비자물가지수',  \n",
    "                     '출생아수',  \n",
    "                    '아파트매매가격지수', '실업자 수']\n",
    "target = ['다음달아파트매매가격']\n",
    "\n",
    "# 시계열 데이터이므로 시간 순서를 고려한 훈련-테스트 데이터 분할\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "X_train, X_test = dataset[features][:train_size], dataset[features][train_size:]\n",
    "y_train, y_test = dataset[target][:train_size], dataset[target][train_size:]\n",
    "\n",
    "# 스케일링 (훈련 세트에만 피팅하고 변환)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = np.clip(scaler_X.transform(X_test),0,1)  # fit_transform이 아닌 transform 사용\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = np.clip(scaler_y.transform(y_test),0,1)\n",
    "\n",
    "# 시계열 데이터 형식으로 변환 (시퀀스 생성)\n",
    "def create_sequences(X, y, seq_length=10):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 10  # 시퀀스 길이 설정\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 조기종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=32, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test_seq)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test_seq, y_pred)\n",
    "R_LSTM_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "R_LSTM_mae = mean_absolute_error(y_test_seq, y_pred)  # MAE 계산\n",
    "R_LSTM_mape = mean_absolute_percentage_error(y_test_seq, y_pred)  # MAPE 계산\n",
    "\n",
    "# 성능 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", R_LSTM_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", R_LSTM_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", R_LSTM_mape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Linear_regression (RMSE): 0.019475396662043253\n",
      "R_XGboost           (RMSE): 0.16182404402349446\n",
      "R_ADAboost          (RMSE): 0.18537297345827197\n",
      "R_Random_Forest     (RMSE): 0.18508364328655993\n",
      "R_Decision_Tree     (RMSE): 0.20688500850965247\n",
      "R_LSTM              (RMSE): 0.022655712428130387\n"
     ]
    }
   ],
   "source": [
    "print(\"R_Linear_regression (RMSE):\", R_regression_rmse)\n",
    "print(\"R_XGboost           (RMSE):\", R_xgboost_rmse)\n",
    "print(\"R_ADAboost          (RMSE):\", R_adaboost_rmse)\n",
    "print(\"R_Random_Forest     (RMSE):\", R_RandomForest_rmse)\n",
    "print(\"R_Decision_Tree     (RMSE):\", R_DecisionTree_rmse)\n",
    "print(\"R_LSTM              (RMSE):\", R_LSTM_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Linear_regression (mae): 0.017274238558609413\n",
      "R_XGboost           (mae): 0.11466812913774457\n",
      "R_ADAboost          (mae): 0.139610490926461\n",
      "R_Random_Forest     (mae): 0.16112410943382516\n",
      "R_Decision_Tree     (mae): 0.1584103537890443\n",
      "R_LSTM              (mae): 0.01998599370320638\n"
     ]
    }
   ],
   "source": [
    "print(\"R_Linear_regression (mae):\", R_regression_mae)\n",
    "print(\"R_XGboost           (mae):\", R_xgboost_mae)\n",
    "print(\"R_ADAboost          (mae):\", R_adaboost_mae)\n",
    "print(\"R_Random_Forest     (mae):\", R_RandomForest_mae)\n",
    "print(\"R_Decision_Tree     (mae):\", R_DecisionTree_mae)\n",
    "print(\"R_LSTM              (mae):\", R_LSTM_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Linear_regression (mape): 0.017280832728600877\n",
      "R_XGboost           (mape): 0.11467960482249943\n",
      "R_ADAboost          (mape): 0.13962414035818224\n",
      "R_Random_Forest     (mape): 0.16113583734072798\n",
      "R_Decision_Tree     (mape): 0.15842529986012555\n",
      "R_LSTM              (mape): 0.01998599370320638\n"
     ]
    }
   ],
   "source": [
    "print(\"R_Linear_regression (mape):\", R_regression_mape)\n",
    "print(\"R_XGboost           (mape):\", R_xgboost_mape)\n",
    "print(\"R_ADAboost          (mape):\", R_adaboost_mape)\n",
    "print(\"R_Random_Forest     (mape):\", R_RandomForest_mape)\n",
    "print(\"R_Decision_Tree     (mape):\", R_DecisionTree_mape)\n",
    "print(\"R_LSTM              (mape):\", R_LSTM_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE3 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case1과 case2의 공통 변수인 \"아파트매매가격, 아파트매매가격지수, 연도별 세대수, 소비자물가지수, 지역내 총생산, 출생아수\" 선정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터분할 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "features = ['아파트매매가격', '지역내총생산', '연도별세대수', \n",
    "            '소비자물가지수', '공급물가지수', '출생아수', '아파트매매가격지수']\n",
    "target = ['다음달아파트매매가격']\n",
    "\n",
    "X = dataset[features]\n",
    "y = dataset[target]\n",
    "\n",
    "# 시계열 데이터이므로 시간 순서를 고려한 훈련-테스트 데이터 분할\n",
    "train_size = int(len(X) * 0.7)  # 데이터의 70%는 학습용, 30%는 테스트용\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    아파트매매가격  지역내총생산  연도별세대수   소비자물가지수  공급물가지수      출생아수  아파트매매가격지수\n",
      "0  0.175666     0.0     0.0  0.000000  111.07  0.981891   0.371728\n",
      "1  0.170294     0.0     0.0  0.038534  111.52  0.704225   0.361257\n",
      "2  0.162879     0.0     0.0  0.041430  112.48  0.770624   0.345550\n",
      "3  0.156756     0.0     0.0  0.040428  112.65  0.726358   0.335079\n",
      "4  0.151855     0.0     0.0  0.058693  111.85  0.700201   0.324607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/1382808373.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[columns_to_scale_X] = scaler_X.fit_transform(X_train[columns_to_scale_X])\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/1382808373.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[columns_to_scale_X] = np.clip(scaler_X.transform(X_test[columns_to_scale_X]),0,1)\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/1382808373.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train[columns_to_scale_y] = scaler_y.fit_transform(y_train[columns_to_scale_y])\n",
      "/var/folders/r7/wm80f9fd57g6h8jt36r8dgwh0000gn/T/ipykernel_48660/1382808373.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test[columns_to_scale_y] = np.clip(scaler_y.transform(y_test[columns_to_scale_y]),0,1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "\n",
    "# 정규화할 열을 선택\n",
    "columns_to_scale_X = ['아파트매매가격', '지역내총생산', '연도별세대수', \n",
    "                      '소비자물가지수', '출생아수', '아파트매매가격지수']\n",
    "columns_to_scale_y = ['다음달아파트매매가격']\n",
    "\n",
    "# 스케일링 적용 (선택한 열들에 대해서만)\n",
    "X_train[columns_to_scale_X] = scaler_X.fit_transform(X_train[columns_to_scale_X])\n",
    "X_test[columns_to_scale_X] = np.clip(scaler_X.transform(X_test[columns_to_scale_X]),0,1)\n",
    "y_train[columns_to_scale_y] = scaler_y.fit_transform(y_train[columns_to_scale_y])\n",
    "y_test[columns_to_scale_y] = np.clip(scaler_y.transform(y_test[columns_to_scale_y]),0,1)\n",
    "\n",
    "# 스케일링된 데이터프레임을 새로운 변수에 저장\n",
    "scaled_X_train = X_train.copy()\n",
    "scaled_X_test = X_test.copy()\n",
    "scaled_y_train = y_train.copy()\n",
    "scaled_y_test = y_test.copy()\n",
    "\n",
    "# 데이터 확인\n",
    "print(scaled_X_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0021065546753186227\n",
      "Root Mean Squared Error (RMSE): 0.04589721860111594\n",
      "Mean Absolute Error (MAE): 0.03426400700300198\n",
      "Mean Absolute Percentage Error (MAPE): 0.03427399610752009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# xgboost 모델 생성 및 학습\n",
    "model = LinearRegression()\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "CR_regression_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "CR_regression_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "CR_regression_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", CR_regression_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", CR_regression_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", CR_regression_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.005417718147287469\n",
      "Root Mean Squared Error (RMSE): 0.07360515027691655\n",
      "Mean Absolute Error (MAE): 0.06425973003267257\n",
      "Mean Absolute Percentage Error (MAPE): 0.06427005774903968\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# xgboost 모델 생성 및 학습\n",
    "model = xgb.XGBRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "CR_xgboost_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "CR_xgboost_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "CR_xgboost_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", CR_xgboost_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", CR_xgboost_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", CR_xgboost_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.031234537379315374\n",
      "Root Mean Squared Error (RMSE): 0.17673295498948513\n",
      "Mean Absolute Error (MAE): 0.14842298252048572\n",
      "Mean Absolute Percentage Error (MAPE): 0.14843326898452788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# adaboost 모델 생성 및 학습\n",
    "model = AdaBoostRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "CR_adaboost_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "CR_adaboost_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "CR_adaboost_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", CR_adaboost_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", CR_adaboost_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", CR_adaboost_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.012387583724299218\n",
      "Root Mean Squared Error (RMSE): 0.11129952256995183\n",
      "Mean Absolute Error (MAE): 0.1089079402435442\n",
      "Mean Absolute Percentage Error (MAPE): 0.10892058266033862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 랜덤 포레스트 모델 생성 및 학습\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "CR_RandomForest_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "CR_RandomForest_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "CR_RandomForest_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", CR_RandomForest_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", CR_RandomForest_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", CR_RandomForest_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.07195484388164652\n",
      "Root Mean Squared Error (RMSE): 0.26824400064427634\n",
      "Mean Absolute Error (MAE): 0.26190336595311575\n",
      "Mean Absolute Percentage Error (MAPE): 0.26192119292849764\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 모델 생성 \n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(scaled_X_train, scaled_y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = regressor.predict(scaled_X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(scaled_y_test, y_pred)\n",
    "CR_DecisionTree_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "CR_DecisionTree_mae = mean_absolute_error(scaled_y_test, y_pred)  # MAE 계산\n",
    "CR_DecisionTree_mape = mean_absolute_percentage_error(scaled_y_test, y_pred)  # MAPE 계산\n",
    "\n",
    "# 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", CR_DecisionTree_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", CR_DecisionTree_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", CR_DecisionTree_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0582 - val_loss: 0.3610\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0202 - val_loss: 0.1759\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0187 - val_loss: 0.2095\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0112 - val_loss: 0.2948\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0099 - val_loss: 0.3402\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0131 - val_loss: 0.3040\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0124 - val_loss: 0.2228\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0079 - val_loss: 0.1417\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.1035\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.1076\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061 - val_loss: 0.1298\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0085 - val_loss: 0.1402\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0070 - val_loss: 0.1269\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0954\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0436\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0166 - val_loss: 0.0064\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0818\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.1402\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0099 - val_loss: 0.1691\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0160 - val_loss: 0.1530\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0116 - val_loss: 0.1065\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0068 - val_loss: 0.0631\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0337\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Mean Squared Error (MSE): 0.00045483373623677416\n",
      "Root Mean Squared Error (RMSE): 0.021326831368883054\n",
      "Mean Absolute Error (MAE): 0.01941222349802653\n",
      "Mean Absolute Percentage Error (MAPE): 0.01941222349802653\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 특성과 타겟 변수 설정\n",
    "features = ['아파트매매가격', '지역내총생산', '연도별세대수', \n",
    "            '소비자물가지수', '공급물가지수', '출생아수', '아파트매매가격지수']\n",
    "target = ['다음달아파트매매가격']\n",
    "\n",
    "# 시계열 데이터이므로 시간 순서를 고려한 훈련-테스트 데이터 분할\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "X_train, X_test = dataset[features][:train_size], dataset[features][train_size:]\n",
    "y_train, y_test = dataset[target][:train_size], dataset[target][train_size:]\n",
    "\n",
    "# 스케일링 (훈련 세트에만 피팅하고 변환)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = np.clip(scaler_X.transform(X_test),0,1)  # fit_transform이 아닌 transform 사용\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = np.clip(scaler_y.transform(y_test),0,1)\n",
    "\n",
    "# 시계열 데이터 형식으로 변환 (시퀀스 생성)\n",
    "def create_sequences(X, y, seq_length=10):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        X_seq.append(X[i:i + seq_length])\n",
    "        y_seq.append(y[i + seq_length])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 10  # 시퀀스 길이 설정\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, seq_length)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 조기종료 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=32, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test_seq)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test_seq, y_pred)\n",
    "CR_LSTM_rmse = np.sqrt(mse)  # RMSE 계산\n",
    "CR_LSTM_mae = mean_absolute_error(y_test_seq, y_pred)  # MAE 계산\n",
    "CR_LSTM_mape = mean_absolute_percentage_error(y_test_seq, y_pred)  # MAPE 계산\n",
    "\n",
    "# 성능 출력\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", CR_LSTM_rmse)\n",
    "print(\"Mean Absolute Error (MAE):\", CR_LSTM_mae)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", CR_LSTM_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR_Linear_regression (RMSE): 0.04589721860111594\n",
      "CR_XGboost           (RMSE): 0.07360515027691655\n",
      "CR_ADAboost          (RMSE): 0.17673295498948513\n",
      "CR_Random_Forest     (RMSE): 0.11129952256995183\n",
      "CR_Decision_Tree     (RMSE): 0.26824400064427634\n",
      "CR_LSTM              (RMSE): 0.021326831368883054\n"
     ]
    }
   ],
   "source": [
    "print(\"CR_Linear_regression (RMSE):\", CR_regression_rmse)\n",
    "print(\"CR_XGboost           (RMSE):\", CR_xgboost_rmse)\n",
    "print(\"CR_ADAboost          (RMSE):\", CR_adaboost_rmse)\n",
    "print(\"CR_Random_Forest     (RMSE):\", CR_RandomForest_rmse)\n",
    "print(\"CR_Decision_Tree     (RMSE):\", CR_DecisionTree_rmse)\n",
    "print(\"CR_LSTM              (RMSE):\", CR_LSTM_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR_Linear_regression (mae): 0.03426400700300198\n",
      "CR_XGboost           (mae): 0.06425973003267257\n",
      "CR_ADAboost          (mae): 0.14842298252048572\n",
      "CR_Random_Forest     (mae): 0.1089079402435442\n",
      "CR_Decision_Tree     (mae): 0.26190336595311575\n",
      "CR_LSTM              (mae): 0.01941222349802653\n"
     ]
    }
   ],
   "source": [
    "print(\"CR_Linear_regression (mae):\", CR_regression_mae)\n",
    "print(\"CR_XGboost           (mae):\", CR_xgboost_mae)\n",
    "print(\"CR_ADAboost          (mae):\", CR_adaboost_mae)\n",
    "print(\"CR_Random_Forest     (mae):\", CR_RandomForest_mae)\n",
    "print(\"CR_Decision_Tree     (mae):\", CR_DecisionTree_mae)\n",
    "print(\"CR_LSTM              (mae):\", CR_LSTM_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR_Linear_regression (mape): 0.03427399610752009\n",
      "CR_XGboost           (mape): 0.06427005774903968\n",
      "CR_ADAboost          (mape): 0.14843326898452788\n",
      "CR_Random_Forest     (mape): 0.10892058266033862\n",
      "CR_Decision_Tree     (mape): 0.26192119292849764\n",
      "CR_LSTM              (mape): 0.01941222349802653\n"
     ]
    }
   ],
   "source": [
    "print(\"CR_Linear_regression (mape):\", CR_regression_mape)\n",
    "print(\"CR_XGboost           (mape):\", CR_xgboost_mape)\n",
    "print(\"CR_ADAboost          (mape):\", CR_adaboost_mape)\n",
    "print(\"CR_Random_Forest     (mape):\", CR_RandomForest_mape)\n",
    "print(\"CR_Decision_Tree     (mape):\", CR_DecisionTree_mape)\n",
    "print(\"CR_LSTM              (mape):\", CR_LSTM_mape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
